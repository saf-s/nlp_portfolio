{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Exploring WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of WordNet\n",
    "WordNet is a lexical database of semantic relationships between words. It organizes nouns, verbs, adjectives, and adverbs into a hierarchy, which are grouped into sets of synonyms called synsets. Synsets may be used to provide short definitions (known as glosses), usage examples, lemmas, hypernyms, hyponyms, meronyms, and holonyms for different words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synsets and Relations of Nouns\n",
    "The code below imports WordNet from NLTK and displays all synsets of the noun \"image\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('image.n.01'),\n",
       " Synset('persona.n.02'),\n",
       " Synset('picture.n.01'),\n",
       " Synset('prototype.n.01'),\n",
       " Synset('trope.n.01'),\n",
       " Synset('double.n.03'),\n",
       " Synset('image.n.07'),\n",
       " Synset('image.n.08'),\n",
       " Synset('effigy.n.01'),\n",
       " Synset('image.v.01'),\n",
       " Synset('visualize.v.01')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.synsets('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below extracts the definition, usage examples, and lemmas of the 'image.n.08' synset of the noun \"image\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition: the general impression that something (a person or organization or product) presents to the public\n",
      "usage examples: ['although her popular image was contrived it served to inspire music and pageantry', 'the company tried to project an altruistic image']\n",
      "lemmas: [Lemma('image.n.08.image')]\n"
     ]
    }
   ],
   "source": [
    "image = wn.synset('image.n.08')\n",
    "print(\"definition:\", image.definition())\n",
    "print(\"usage examples:\", image.examples())\n",
    "print(\"lemmas:\", image.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below traverses up the WordNet hierarchy from the 'image.n.08' synset of the noun \"image\". It uses the function 'hyper' and the NLTK method 'closure()' to return the hypernym of the synset.\n",
    "\n",
    "WordNet organizes nouns such that there is a constant top-level synset for all nouns. The top level of the hierarchy for nouns has the noun \"entity\", which the hierarchy traverses up to from a given noun synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('impression.n.02'),\n",
       " Synset('appearance.n.01'),\n",
       " Synset('quality.n.01'),\n",
       " Synset('attribute.n.02'),\n",
       " Synset('abstraction.n.06'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = lambda s: s.hypernyms()\n",
    "list(image.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays the hypernyms (higher), hyponyms (lower), meronyms (part of), holonyms (whole), and antonyms (opposite) of the 'image.n.08' synset, if they exist. The synset's lemma is used to find antonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypernyms: [Synset('impression.n.02')]\n",
      "hyponyms: []\n",
      "meronyms: []\n",
      "holonyms: []\n",
      "antonyms: []\n"
     ]
    }
   ],
   "source": [
    "print(\"hypernyms:\", image.hypernyms())\n",
    "print(\"hyponyms:\", image.hyponyms())\n",
    "print(\"meronyms:\", image.part_meronyms())\n",
    "print(\"holonyms:\", image.part_holonyms())\n",
    "print(\"antonyms:\", image.lemmas()[0].antonyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synsets and Relations of Verbs\n",
    "The code below displays all synsets of the verb \"consume\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('devour.v.03'),\n",
       " Synset('consume.v.02'),\n",
       " Synset('consume.v.03'),\n",
       " Synset('consume.v.04'),\n",
       " Synset('consume.v.05'),\n",
       " Synset('consume.v.06')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('consume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below extracts the definition, usage examples, and lemmas of the 'consume.v.05' synset of the verb \"consume\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition: use up (resources or materials)\n",
      "usage examples: ['this car consumes a lot of gas', 'We exhausted our savings', 'They run through 20 bottles of wine a week']\n",
      "lemmas: [Lemma('consume.v.05.consume'), Lemma('consume.v.05.eat_up'), Lemma('consume.v.05.use_up'), Lemma('consume.v.05.eat'), Lemma('consume.v.05.deplete'), Lemma('consume.v.05.exhaust'), Lemma('consume.v.05.run_through'), Lemma('consume.v.05.wipe_out')]\n"
     ]
    }
   ],
   "source": [
    "consume = wn.synset('consume.v.05')\n",
    "print(\"definition:\", consume.definition())\n",
    "print(\"usage examples:\", consume.examples())\n",
    "print(\"lemmas:\", consume.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below traverses up the WordNet hierarchy from the 'consume.v.05' synset of the verb \"consume\". It uses the function 'hyper' and the NLTK method 'closure()' to return the hypernym of the synset.\n",
    "\n",
    "WordNet organizes verbs such that there is no constant top-level synset for all verbs. Tracing the synset for the verb \"consume\" gives \"spend\" as the hypernym, the verb \"spend\" gives \"pay\" as the hypernym, and so on. The verbs \"spend\" and \"pay\" are not very similar semantically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('spend.v.02'),\n",
       " Synset('pay.v.01'),\n",
       " Synset('give.v.03'),\n",
       " Synset('transfer.v.05')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = lambda s: s.hypernyms()\n",
    "list(consume.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses the 'morphy()' function to find different forms of the verb \"consume\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'consume'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('consume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy('consume', wn.ADJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'consume'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('consume', wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy('consume', wn.NOUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy('consume', wn.ADV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Similarity and Comparison\n",
    "The code below finds and defines the synsets of two similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synset of 'thief': [Synset('thief.n.01')]\n",
      "definition of 'thief': a criminal who takes property belonging to someone else with the intention of keeping it or selling it\n",
      "\n",
      "synset of 'robber': [Synset('robber.n.01')]\n",
      "definition of 'robber': a thief who steals from someone by threatening violence\n"
     ]
    }
   ],
   "source": [
    "print(\"synset of 'thief':\", wn.synsets('thief'))\n",
    "print(\"definition of 'thief':\", wn.synset('thief.n.01').definition())\n",
    "print()\n",
    "print(\"synset of 'robber':\", wn.synsets('robber'))\n",
    "print(\"definition of 'robber':\", wn.synset('robber.n.01').definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below runs the Wu-Palmer similarity metric to measure the similarity between the words \"thief\" and \"robber\". It uses the depth of the words and common ancestor words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thief = wn.synset('thief.n.01')\n",
    "robber = wn.synset('robber.n.01')\n",
    "wn.wup_similarity(thief, robber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below runs the Lesk algorithm using the words \"thief\" and \"robber\". This algorithm looks at context words for each word using the given sentences and compares them to words in dictionary glosses to return a synset that has the highest count of overlapping words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output for 'thief' after algorithm: Synset('thief.n.01')\n",
      "output for 'robber' after algorithm: Synset('robber.n.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "thief_sent = ['The', 'thief', 'was', 'caught', 'and', 'went', 'to', 'jail', '.']\n",
    "print(\"output for 'thief' after algorithm:\", lesk(thief_sent, 'thief'))\n",
    "\n",
    "robber_sent = ['The', 'robber', 'was', 'caught', 'and', 'went', 'to', 'jail', '.']\n",
    "print(\"output for 'robber' after algorithm:\", lesk(robber_sent, 'robber'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordNet\n",
    "SentiWordNet is a lexical resource that is built on top of WordNet. It assigns 3 sentiment scores between 0.0 and 1.0, with the scores adding up to 1.0, for each synset: positivity, negativity, and objectivity. SentiWordNet can be useful for sentiment analysis or opinion mining.\n",
    "\n",
    "The code below downloads and imports SentiWordNet from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below finds senti-synsets for the word \"move\" and displays the polarity scores for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<move.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<move.n.02: PosScore=0.0 NegScore=0.0>\n",
      "<motion.n.03: PosScore=0.0 NegScore=0.125>\n",
      "<motion.n.06: PosScore=0.0 NegScore=0.0>\n",
      "<move.n.05: PosScore=0.0 NegScore=0.0>\n",
      "<travel.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.02: PosScore=0.25 NegScore=0.0>\n",
      "<move.v.03: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.04: PosScore=0.0 NegScore=0.0>\n",
      "<go.v.02: PosScore=0.0 NegScore=0.0>\n",
      "<be_active.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.07: PosScore=0.0 NegScore=0.0>\n",
      "<act.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<affect.v.05: PosScore=0.125 NegScore=0.125>\n",
      "<motivate.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.11: PosScore=0.375 NegScore=0.25>\n",
      "<move.v.12: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.13: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.14: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.15: PosScore=0.0 NegScore=0.0>\n",
      "<move.v.16: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "move = swn.senti_synsets('move')\n",
    "for item in move:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays the polarity for each word in a given sentence, after tokenization.\n",
    "\n",
    "The scores display how positive or negative a word may be, where many words in the sentence have a neutral polarity. Knowing polarity scores can be useful in NLP applications, such as for text processing by analyzing the sentiment of text to see if it is positive or negative and objective or subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Cats\n",
      "polarity for <cat.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <guy.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <cat.n.03: PosScore=0.0 NegScore=0.125>\n",
      "polarity for <kat.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <cat-o'-nine-tails.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <caterpillar.n.02: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <big_cat.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <computerized_tomography.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <cat.v.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <vomit.v.01: PosScore=0.0 NegScore=0.0>\n",
      "\n",
      "word: are\n",
      "polarity for <are.n.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.01: PosScore=0.25 NegScore=0.125>\n",
      "polarity for <be.v.02: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.03: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <exist.v.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.05: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <equal.v.01: PosScore=0.125 NegScore=0.125>\n",
      "polarity for <constitute.v.01: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.08: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <embody.v.02: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.10: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.11: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <be.v.12: PosScore=0.0 NegScore=0.0>\n",
      "polarity for <cost.v.01: PosScore=0.0 NegScore=0.0>\n",
      "\n",
      "word: fun\n",
      "polarity for <fun.n.01: PosScore=0.375 NegScore=0.0>\n",
      "polarity for <fun.n.02: PosScore=0.0 NegScore=0.5>\n",
      "polarity for <fun.n.03: PosScore=0.125 NegScore=0.125>\n",
      "polarity for <playfulness.n.02: PosScore=0.0 NegScore=0.0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = 'Cats are fun'\n",
    "tokens = sent.split()\n",
    "for token in tokens:\n",
    "    print(\"word:\", token)\n",
    "    syn_list = swn.senti_synsets(token)\n",
    "    for item in syn_list:\n",
    "        print(\"polarity for\", item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations and Mutual Information\n",
    "A collocation is when two or more words occur next to each other more often than expected by chance. A collocation of two words cannot be replaced by synonyms as the semantic of the words is different when they exist together than when they exist as separate words.\n",
    "\n",
    "The code below imports NLTK Text objects from the book collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays all collocations for the 'text4' Text object using the 'collocations()' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below calculates mutual information for the collocation 'United States'. The point-wise mutual information (pmi) formula shows that the log of the probability of \"United\" and \"States\" occuring together divided by the probability of them occuring separately results in a higher value compared to the count of each of the two word from the total number of words in the Text object. As the pmi for \"United States\" is positive, the words \"United\" and \"States\" appear together more frequently than expected chance and can thus be a collocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(United States) =  0.015860349127182045\n",
      "p(United) =  0.0170573566084788\n",
      "p(States) =  0.03301745635910224\n",
      "pmi =  4.815657649820885\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "text = ' '.join(text4.tokens)\n",
    "text[:50]\n",
    "\n",
    "vocab = len(set(text4))\n",
    "us = text.count('United States')/vocab\n",
    "print(\"p(United States) = \", us)\n",
    "u = text.count('United')/vocab\n",
    "print(\"p(United) = \", u)\n",
    "s = text.count('States')/vocab\n",
    "print('p(States) = ', s)\n",
    "pmi = math.log2(us / (u * s))\n",
    "print('pmi = ', pmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ba252fe723dbf5b4005d1597e15f6f84190629abaf2b8c0ec9e30f106cffba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
